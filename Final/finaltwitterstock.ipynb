{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a list of all words on the stopwords txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = open('stopwords.txt', 'r')\n",
    "stopword = []\n",
    "for line in stop:\n",
    "    line = line.split()\n",
    "    stopword.extend(line)\n",
    "stop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a list of all the tickers and common name of the company\n",
    "the file's columns are split with a dash, so use the parameter \" - \" to ensure the dashes in company names are not being split upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorthand = open('shorthandstock.txt','r')\n",
    "shstock = []\n",
    "for line in shorthand:\n",
    "    line = line.lower().strip()\n",
    "    line = line.split(' - ')\n",
    "    shstock.extend(line)\n",
    "#     for word in line:\n",
    "#         word = word.strip()\n",
    "#         shstock.append(word)\n",
    "shorthand.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove any common words (stop words) using the previously created lists\n",
    "this lessens any misinterpretations of the results, since stop words may be used without the correct context we are looking at (i.e. the word 'a' is used in a lot of sentences without being about a specific stock NOR the stock ticker 'A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in shstock:\n",
    "    for word in stopword:\n",
    "        if ticker == word:\n",
    "            shstock.remove(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the same process for assignment 1, we will replace any special characters (including those commonly used in twitter, such as the hashtag), lowercase the words, and add it to a list of twitterwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterwords = open('twitterstock.txt')\n",
    "tweets = []\n",
    "for line in twitterwords:\n",
    "    result = line.replace(':','').replace('?','')\\\n",
    "    .replace(',','').replace('.','').replace('\"','')\\\n",
    "    .replace('!','').replace('(','').replace(')','')\\\n",
    "    .replace('\\'','').replace('\\\\','')\\\n",
    "    .replace('/','').replace('$','').replace('#','')\n",
    "    result = result.strip().lower()\n",
    "    result = result.split()\n",
    "    tweets.extend(result)\n",
    "twitterwords.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to assignment 1, we will create a dictionary to keep track of how many of the words found in the tweets match any company ticker or company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetstocks = {}\n",
    "for word in shstock:\n",
    "    count = 0\n",
    "    if word not in tweetstocks:\n",
    "        tweetstocks[word] = 0\n",
    "    for tweet in tweets:\n",
    "        if word == tweet:\n",
    "            count += 1\n",
    "            tweetstocks[word] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will return a list of 10 words from the dictionary whose value is highest -- from here we will determine, using intuition, which specific company to look at based on the results\n",
    "\n",
    "can return the top 10 list using lambda function OR\n",
    "create a sorted list and new sorted dictionary of top 10 values\n",
    "\n",
    "intuition is necessary as some company tickers are also common words. to ensure a better/more accurate interpretation, we will ignore common words (i.e. new, ceo, big) and look at more uncommon tickers/company names (i.e. RM, APHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 243),\n",
       " ('fit', 87),\n",
       " ('save', 84),\n",
       " ('big', 69),\n",
       " ('ceo', 60),\n",
       " ('rm', 52),\n",
       " ('eye', 46),\n",
       " ('free', 40),\n",
       " ('apha', 34),\n",
       " ('pro', 34)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tweetstocks.items(), key=lambda x:x[1],\\\n",
    "       reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new': 243,\n",
       " 'fit': 87,\n",
       " 'save': 84,\n",
       " 'big': 69,\n",
       " 'ceo': 60,\n",
       " 'rm': 52,\n",
       " 'eye': 46,\n",
       " 'free': 40,\n",
       " 'apha': 34,\n",
       " 'pro': 34}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortw = sorted(tweetstocks, \\\n",
    "               key=tweetstocks.get, reverse=True)[:10]\n",
    "\n",
    "top10 = {}\n",
    "\n",
    "for w in sortw:\n",
    "    top10[w] = tweetstocks[w]\n",
    "    \n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
